
# ğŸ’¬ Personal Notes Q&A Chatbot (Local or Cloud LLM)

This is a simple yet powerful **personal assistant chatbot** that can answer questions from your own notes using embeddings and any LLM â€” either cloud-based (OpenAI) or completely local (via [Ollama](https://ollama.com)).

> ğŸ” Your data stays private. You own your files and your compute.

---

## ğŸš€ Features

- ğŸ” Ask questions about your own notes
- ğŸ“ Supports `.txt` files (extensible to PDF, CSV, etc.)
- ğŸ¤– Works with OpenAI **or** local models like `deepseek-coder`, `mistral`, etc.
- ğŸ’¡ Embedding-based semantic search (vector store)
- ğŸ”Œ Pluggable LLM backend â€” add your own easily
- ğŸ’» Runs locally with no internet if using Ollama

---

## ğŸ§± Project Structure

```
my-chatbot/
â”œâ”€â”€ main.py                     # Main CLI chatbot
â”œâ”€â”€ config.yaml                 # Backend + model config
â”œâ”€â”€ notes/
â”‚   â””â”€â”€ my_notes.txt            # Your personal notes (can modify this)
â”œâ”€â”€ llm_backends/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ openai_backend.py       # LLM wrapper for OpenAI
â”‚   â””â”€â”€ local_backend.py        # LLM wrapper for Ollama/local model
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Setup Instructions

### 1. ğŸ”§ Prerequisites

- Python 3.8+
- (Optional) [Ollama](https://ollama.com) for local models like `deepseek-coder`
- Your notes in `notes/my_notes.txt`

---

### 2. ğŸ“¦ Install Dependencies

```bash
git clone https://github.com/your-username/my-chatbot.git
cd my-chatbot
pip install -r requirements.txt
```

---

### 3. âœï¸ Add Your Notes

Replace or edit the contents of `notes/my_notes.txt` with your personal notes or text files you'd like to ask questions about.

---

### 4. âš™ï¸ Configure the Backend

Edit `config.yaml` to choose your model:

#### ğŸ‘‰ Option 1: Using **OpenAI API**
```yaml
llm_backend: openai
openai_api_key: "sk-..."  # replace with your actual key
```

#### ğŸ‘‰ Option 2: Using **Ollama Local Model**
```yaml
llm_backend: local
local_llm_url: "http://localhost:11434"
local_llm_model: "deepseek-coder:1.5b"  # or "mistral", etc.
```

> Run your model using:
```bash
ollama run deepseek-coder:1.5b
```

---

### 5. ğŸ§  Run the Chatbot

```bash
python main.py
```

Example:
```
> What is the summary of my project notes?

A: Your project notes discuss the architecture of...
```

Type `exit` to quit.

---

## ğŸ§  How It Works

1. Splits your notes into chunks
2. Uses **sentence-transformers** to create vector embeddings
3. Stores embeddings in **FAISS** (vector database)
4. When you ask a question:
   - Embeds your query
   - Finds the most relevant chunks
   - Feeds them to the LLM as context to answer

---

## ğŸ› Easily Extend or Customize

- âœ… Add support for PDF/Markdown: via `PyMuPDF`, `markdown`, or `pdfplumber`
- âœ… Plug in your own LLM via `llm_backends/`
- âœ… Wrap it in a GUI or convert it into a Chrome extension

---

## ğŸ¤– Example Models to Try with Ollama

```bash
ollama pull deepseek-coder:1.5b
ollama pull mistral
ollama pull llama2
ollama pull phi
```

Then just update `config.yaml` with the name!

---

## ğŸ“Œ Requirements

```
faiss-cpu
sentence-transformers
openai
requests
pyyaml
```

Install via:

```bash
pip install -r requirements.txt
```

---

## ğŸ“„ License

MIT License â€” free for personal or commercial use.

---

## ğŸ™‹ Support & Ideas

Feel free to open issues or pull requests if you want to add:

- Multiple note files
- Browser extension
- GUI frontend
- Whisper integration for voice input

---

> Created with ğŸ’¡ by [Banu Saladi]
